# Naver Webtoon All rating crawler

â­ìš”ì¼ë³„ ëª¨ë“  ì›¹íˆ°ë“¤ì˜ ì „ì²´ í™”ì˜ í‰ì ì„ ê° íŒŒì¼ë³„ë¡œ ë‚˜ëˆ„ì–´ í¬ë¡¤ë§í•´ì˜¤ëŠ” í”„ë¡œê·¸ë¨â­

```go
//ìŠ¤í¬ë˜í•‘ ëŒ€ìƒ URL

const (
	urlRoot    = "https://comic.naver.com/webtoon/weekday.nhn"
	urlSubRoot = "https://comic.naver.com"
)
```


## Stack
|           |     Crawler      |
|:---------:|:---------:|
| Developer | ì œì •ë¯¼ | 
| Develop Language | GO |  
| Develop Tool     | Visual Studio Code|

### í”„ë¡œì íŠ¸ ì§„í–‰ ë‹¨ê³„   
> 1ì¼ì°¨ - ğŸŒŸë„¤ì´ë²„ ì›¹íˆ° ë©”ì¸í˜ì´ì§€ì„œ ëª¨ë“  ì›¹íˆ°ì„ ê³ ë£¨í‹´(ì“°ë ˆë“œ)ë¥¼ í†µí•´ ì´ë™ í›„ í˜ì´ì§€ í‰ì  ì •ë³´ë¥¼ ê°€ì§€ê³  ì˜´.<br/>
> 2ì¼ì°¨ - ğŸ¤¹ìƒê°ë³´ë‹¤ ë„ˆë¬´ ì‰¬ì›Œì„œ ëª¨ë“  ì›¹íˆ°ì˜ ìµœê·¼ 10í™”ë¥¼ ê³ ë£¨í‹´(ì“°ë ˆë“œ)ë¥¼ í†µí•´ 2ì°¨ ì´ë™ í›„ ì°¸ì—¬ì ìˆ˜ë„ ê°€ì§€ê³  ì˜´.<br/>
> 3ì¼ì°¨ - ğŸ›ìê¾¸ ì—ëŸ¬ê°€ ë– ì„œ ë¡œê·¸ë¥¼ ì°ì–´ë³´ë‹¤ê°€ 19ê¸ˆ ì›¹íˆ°ì—ì„œ ë§‰íˆëŠ” ê²ƒì„ ë°œê²¬í•˜ê³  ê³ ì¹¨<br/>
> 4ì¼ì°¨ - ğŸ‘¨â€ğŸ’»ë§ˆì§€ë§‰ìœ¼ë¡œ íŒŒì¼ ì…ì¶œë ¥ ì²˜ë¦¬ì— ê´€í•œ ë¬¸ì œë¥¼ ë°œê²¬í•˜ê³  ì˜¤ë¥˜ ìˆ˜ì •<br/>


### ğŸ§µ ëª¨ë“  ì›¹íˆ°ì„ ê³ ë£¨í‹´ì„ í†µí•´ ì´ë™í•˜ëŠ” ì½”ë“œ

```go
//classê°€ titleì¸(ëª¨ë“ ) ì›¹íˆ°ë“¤ ëŒ€ìƒìœ¼ë¡œ ì›í•˜ëŠ” URLíŒŒì‹± í›„ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
func parseMainNodes(n *html.Node) bool {
	if n.DataAtom == atom.A && n.Parent != nil {
		return scrape.Attr(n, "class") == "title"
	}
	return false
}
```

```go
urlList := scrape.FindAll(root, parseMainNodes)

	//ì›¹íˆ°ë“¤ ì „ë¶€ ê¸ì–´ì™€ì„œ for rangeë¡œ ìˆœíšŒ
	for _, link := range urlList {
		// //ëŒ€ìƒ URL ì¶œë ¥
		// fmt.Println("Mon Link : ", link, idx)
		// //ì›¹íˆ° ì œëª©
		// fmt.Println(scrape.Attr(link, "title"))

		fileName := scrape.Attr(link, "title")
		fmt.Println("filename is : ", fileName)

		//ì‘ì—… ëŒ€ê¸°ì—´ì— ê³ ë£¨í‹´ì´ ë‹¤ ëë‚ ë•Œê¹Œì§€ ê¸°ë‹¤ë¦´ ìˆ˜ ìˆê²Œ ì¶”ê°€
		wg.Add(1) //Done ê°œìˆ˜ì™€ ì¼ì¹˜

		//ê³ ë£¨í‹´ ì‹œì‘ -> ì‘ì—… ëŒ€ê¸°ì—´ ê°œìˆ˜ì™€ ê°™ì•„ì•¼ í•¨.
		go scrapContents(scrape.Attr(link, "href"), fileName)
	}
```
<img width="1440" alt="Screen Shot 2019-12-19 at 20 26 54" src="https://user-images.githubusercontent.com/52072077/71170170-f131bd00-229d-11ea-935c-0daf82572cc9.png">

### âœ… ê³ ë£¨í‹´ì´ ìˆë‹¤ë©´ ë™ê¸°í™”ê°€ í•„ìˆ˜
```go
//ë™ê¸°í™”ë¥¼ ìœ„í•œ ì‘ì—… ê·¸ë£¹ ì„ ì–¸
var wg sync.WaitGroup
var mutex = &sync.Mutex{}
```

### ğŸ‘‰ GOì–¸ì–´ë¥¼ ì‚¬ìš©í•œë‹¤ë©´ ì—ëŸ¬ì²´í¬ë„ í•„ìˆ˜ 
```go
//ì—ëŸ¬ì²´í¬í•  í•¨ìˆ˜ ì„ ì–¸í•˜ì—¬ ê³„ì† ì‚¬ìš©í•´ì¤Œ.
func errCheck(err error) {
	if err != nil {
		log.Fatal(err)
	}
}
```

### ğŸ§µ ëª¨ë“  ì›¹íˆ°ì˜ ìµœê·¼ 10í™” ì›¹íˆ°ì„ ê³ ë£¨í‹´ì„ í†µí•´ ë“¤ì–´ê°€ëŠ” ì½”ë“œ
```go
//<td class="title"> ìµœê·¼ 10í™” ì›¹íˆ° ì‚¬ì´íŠ¸ë“¤ íƒœê·¸ ê¸ì–´ì˜¤ëŠ” í•¨ìˆ˜
func parseSubNodes(n *html.Node) bool {
	// return n.Parent.DataAtom == atom.Td && scrape.Attr(n, "class") == "title"
	if n.DataAtom == atom.A && n.Parent != nil {
		return scrape.Attr(n.Parent, "class") == "title"
	}
	return false
}
```

```go
recentList := scrape.FindAll(root, parseSubNodes)

	//parseSubNodes í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•´ì„œ ì›í•˜ëŠ” ë…¸ë“œ ìˆœíšŒ(í‰ì  ê¸ì–´ì˜¤ê¸°)í•˜ë©´ì„œ ì¶œë ¥
	//<td class="title"> ìµœê·¼ 10í™” ì›¹íˆ° ì‚¬ì´íŠ¸ íƒœê·¸
	for _, link := range recentList {
		//ë™ê¸°í™”
		wg.Add(1)
		mutex.Lock()
		//í•´ë‹¹ ë°ì´í„° ì¶œë ¥
		go scrapRatingType(scrape.Attr(link, "href"), fn)
		//íŒŒì‹± ë°ì´í„° -> ë²„í¼ì— ê¸°ë¡
		// w.WriteString(scrape.Text(g) + "\r\n")
	}
	// w.Flush()
```

<img width="1440" alt="Screen Shot 2019-12-19 at 20 26 19" src="https://user-images.githubusercontent.com/52072077/71170174-f2fb8080-229d-11ea-9d89-ad3484194c3d.png">

### ğŸ‘¨â€ğŸ’» ì›¹íˆ°ë“¤ì˜ í‰ì ê³¼ ì°¸ì—¬ì ìˆ˜ ì •ë³´ë¥¼ ê°€ì§€ê³ ì˜¤ëŠ” ì½”ë“œ

```go
//<div class="..." id="topTotalStarPoint"> ê°€ ìˆëŠ” ì½”ë“œë“¤ ê¸ì–´ì˜¤ëŠ” í•¨ìˆ˜
func parseStarNodes(n *html.Node) bool {
	return n.DataAtom == atom.Div && scrape.Attr(n, "id") == "topTotalStarPoint"
}
```

<img width="1440" alt="Screen Shot 2019-12-19 at 20 26 41" src="https://user-images.githubusercontent.com/52072077/71170177-f4c54400-229d-11ea-8e2f-49b2800e23df.png">

### ğŸ—’ï¸ ì›¹íˆ°ì´ë¦„.txt íŒŒì¼ì— í‰ì ê³¼ ì°¸ì—¬ì ìˆ˜ë¥¼ ìë™ìœ¼ë¡œ ì‘ì„±í•´ì£¼ëŠ” ì½”ë“œ
```go
//íŒŒì¼ ìŠ¤í¬ë¦¼ ìƒì„±(ì—´ê¸°) -> íŒŒì¼ëª…, ì˜µì…˜, ê¶Œí•œ
	file, err := os.OpenFile("/Users/jejeongmin/documents/go/src/NaverWebtoon_crawler/Scrape/"+fn+".txt", os.O_APPEND|os.O_CREATE|os.O_RDWR, os.FileMode(0777))
	//ì—ëŸ¬ì²´í¬
	errCheck(err)

	//ë©”ì†Œë“œ ì¢…ë£Œ ì‹œ íŒŒì¼ ë‹«ì•„ì•¼ í•¨
	defer file.Close()

	//ì“°ê¸° ë²„í¼ ì„ ì–¸
	w := bufio.NewWriter(file)

	for _, g := range scrape.FindAll(root, parseStarNodes) {
		//URL ë° í•´ë‹¹ ë°ì´í„° ì¶œë ¥
		fmt.Println("result : ", scrape.Text(g))
		//íŒŒì‹± ë°ì´í„° -> ë²„í¼ì— ê¸°ë¡
		w.WriteString(scrape.Text(g) + "\r\n")
	}
	w.Flush()
```


<img width="1440" alt="Screen Shot 2019-12-19 at 19 59 29" src="https://user-images.githubusercontent.com/52072077/71168499-318f3c00-229a-11ea-9004-84e12504b3dc.png">



